{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(len(os.listdir(\"D:\\\\Studia\\\\thesis\\\\data\\\\KillerWhale\")))\n",
    "\n",
    "num_of_files = 0\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(\"D:\\\\Studia\\\\thesis\\\\data\"):\n",
    "    num_of_files+= len(filenames)\n",
    "    \n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}\")\n",
    "print(num_of_files)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly I am going through all elements in the dataset and I am creating dataframe with path to the sample and corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import wave\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "directory_path = \"D:\\\\Studia\\\\thesis\\\\data\"\n",
    "\n",
    "#paths to subfolders\n",
    "subdirectories = [os.path.join(directory_path, d) for d in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, d))]\n",
    "print(subdirectories)\n",
    "\n",
    "longest_sample = 0\n",
    "shortest_sample = 5\n",
    "\n",
    "#Creating dataframe out of paths and and names\n",
    "df=[]\n",
    "for subdirectory in subdirectories:\n",
    "    #Every sample that is not killer whale is labeled 0, killer whale samples are labeled 1\n",
    "    label = os.path.basename(subdirectory)\n",
    "    ID=0\n",
    "    if label==\"KillerWhale\":\n",
    "        ID=1\n",
    "        \n",
    "    paths_and_labels = []\n",
    "    \n",
    "    for file in os.listdir(subdirectory):\n",
    "        file_path = os.path.join(subdirectory, file)\n",
    "        paths_and_labels.append([file_path, ID])\n",
    "        \n",
    "        #I want to check the length of shortest and longest sample\n",
    "        with wave.open(file_path, 'r') as f:\n",
    "            frames = f.getnframes()\n",
    "            frame_rate = f.getframerate()\n",
    "            duration = frames / float(frame_rate)\n",
    "        if duration>longest_sample:\n",
    "            longest_sample=duration\n",
    "        if duration<shortest_sample:\n",
    "            shortest_sample=duration\n",
    "    \n",
    "    dataframe = pd.DataFrame(paths_and_labels, columns=['Path', 'ID'])\n",
    "    df.append(dataframe)\n",
    "    \n",
    "#I am creating a single dataframe of all elements  \n",
    "ready_df = pd.concat(df, ignore_index = True)\n",
    "\n",
    "#Here I am shuffling the dataset\n",
    "ready_df = ready_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(\"There is {} Killer Whale samples and {} samples of diffrent species\".format(len(os.listdir(\"D:\\\\Studia\\\\thesis\\\\data\\\\KillerWhale\")), num_of_files-len(os.listdir(\"D:\\\\Studia\\\\thesis\\\\data\\\\KillerWhale\"))))\n",
    "print(\"longest sample duration:\", longest_sample, \"seconds\")\n",
    "print(\"shortest sample duration:\", shortest_sample, \"seconds\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I the cell below I am converting audio samples into MFCCs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import mat\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "list_of_paths = ready_df[\"Path\"].tolist()\n",
    "list_of_ID = ready_df[\"ID\"].tolist()\n",
    "\n",
    "json_path_scaled = \"MFCC_data_scaled.json\"\n",
    "\n",
    "duration = 1 #seconds\n",
    "sample_rate = 16000\n",
    "samples_per_track=sample_rate * duration\n",
    "\n",
    "data = {\"mfcc\" : [],\n",
    "        \"label\" : [],\n",
    "        \"frequency\": [],\n",
    "        \"duration\": [],\n",
    "        \"pitch\": []\n",
    "        }\n",
    "\n",
    "data_scaled = {\"mfcc\" : [],\n",
    "               \"label\" : [],\n",
    "               \"frequency\": [],\n",
    "               \"duration\": [],\n",
    "               \"pitch\": []\n",
    "              }\n",
    "\n",
    "#Next three functions are supposed to extract frequency, duration and pitch from the given sample.\n",
    "def extract_frequency(signal, sr):\n",
    "    fourier_transform = np.fft.rfft(signal)\n",
    "    abs_fourier_transform = np.abs(fourier_transform)\n",
    "    frequency = np.argmax(abs_fourier_transform)\n",
    "    return frequency\n",
    "\n",
    "def extract_duration(signal, sr):\n",
    "    duration = len(signal) / sr\n",
    "    return duration\n",
    "\n",
    "def extract_pitch(signal, sr):\n",
    "    pitches, magnitudes = librosa.piptrack(y=signal, sr=sr)\n",
    "    # I am trying to find the index of the maximum value in magnitudes along the frequency. when I am using pitch = pitches[np.argmax(magnitudes)], it returns the position of the maximum value as if the 2D array was stretched out into a single line, which leads to an error.\n",
    "    # On Stackoverflow website I found function np.unravel_index. Cited meaning: \"function takes the flattened position and converts it back into two positions: one for the time dimension and one for the frequency dimension. These two positions should correctly point to the maximum value in the 2D array.\" \n",
    "    f_index, t_index = np.unravel_index(np.argmax(magnitudes), magnitudes.shape) \n",
    "    pitch = pitches[f_index, t_index]\n",
    "    return pitch  \n",
    "     \n",
    "     \n",
    "#This is a function which should add noise to given sample. It is used for data augmentation.   \n",
    "def add_noise(signal):\n",
    "    noise = np.random.normal(0, 0.005, signal.shape)\n",
    "    return signal + noise\n",
    "\n",
    "\n",
    "\n",
    "#This function calculates the MFCCs of the audio file located at path and appends them, along with other features, to the data_scaled dictionary. \n",
    "#It also segments the audio signal and computes MFCCs for each segment. If augmentation_fn is provided, it applies this function to the signal for data augmentation.\n",
    "def spectro(path, i, n_mfcc=13, n_fft=2048, hop_length=512, num_segments=5, augmentation_fn=None):\n",
    "\n",
    "    signal, sr = librosa.load(path, sr=sample_rate)\n",
    "    while len(signal) < samples_per_track:\n",
    "        signal = np.concatenate((signal, signal[:samples_per_track - len(signal)]))\n",
    "    num_samples_per_segment=int(samples_per_track / num_segments)\n",
    "    expected_num_mfcc_per_segment= math.ceil(num_samples_per_segment / hop_length)\n",
    "    \n",
    "    if augmentation_fn:\n",
    "        signal = augmentation_fn(signal)\n",
    "    \n",
    "    #process every segment\n",
    "    for s in range(num_segments):\n",
    "        start_sample = num_samples_per_segment * s\n",
    "        finish_sample = start_sample + num_samples_per_segment\n",
    "    \n",
    "        #transforming audio into mfcc\n",
    "        mfcc = librosa.feature.mfcc(y=signal[start_sample:finish_sample],\n",
    "                                    sr=sr,\n",
    "                                    n_fft=n_fft,\n",
    "                                    n_mfcc=n_mfcc,\n",
    "                                    hop_length=hop_length\n",
    "                                    )\n",
    "        mfcc = mfcc.T\n",
    "        if len(mfcc) == expected_num_mfcc_per_segment:\n",
    "            scaler = StandardScaler()\n",
    "            mfcc_scaled = scaler.fit_transform(mfcc)\n",
    "            data_scaled[\"mfcc\"].append(mfcc_scaled.tolist()) #numpy array changed into a list\n",
    "            data_scaled[\"label\"].append(list_of_ID[i])\n",
    "            data_scaled[\"frequency\"].append(extract_frequency(signal, sr))\n",
    "            data_scaled[\"duration\"].append(extract_duration(signal, sr))\n",
    "            data_scaled[\"pitch\"].append(extract_pitch(signal, sr))\n",
    "            \n",
    "#This variable determines how many times the minority class will be oversampled.       \n",
    "upsampling_factor = 4        \n",
    " \n",
    "#For each file, it extracts features and appends them to data_scaled.\n",
    "#If the label is 1 (indicating the minority class), the signal is augmented and the features are extracted again multiple times, according to the upsampling factor.       \n",
    "for i in range(0, len(list_of_paths)-1):\n",
    "    path = list_of_paths[i]\n",
    "    label = list_of_ID[i]\n",
    "    spectro(path,i)\n",
    "    \n",
    "    if label == 1:\n",
    "        for j in range(upsampling_factor-1):\n",
    "            spectro(path, i, augmentation_fn=add_noise)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code we save numpy dataframe into a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NumpyEncoder, self).default(obj)\n",
    "\n",
    "\n",
    "    \n",
    "with open(json_path_scaled, \"w\") as fp:\n",
    "    json.dump(data_scaled, fp, cls=NumpyEncoder, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
